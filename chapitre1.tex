\addtocounter{chapter}{-3}
\chapter{Compléments d'algèbre linéaire}
\minitoc
\minilof
\minilot

Dans tout le chapitre $\K$ désigne l'un des corps $\R$ ou $\C$.
\section{Structures}
\subsection{Applications à valeur dans un espace vectoriel}
Soit $\S$ un ensemble quelconque et $(E,+,\cdot)$ un $\K$-espace vectoriel. L'ensemble $\F(\S,E) = E^{\S}$ des applications de $\S$ dans $E$ est naturellement muni des lois interne et externe suivantes, encore notées $+$ et $\cdot$~:
\begin{itemize}
	\item pour $f$ et $g$ dans $\F(\S,E)$, on définit une application $f+g$ de $\S$ dans $E$ telle que~:
	\begin{equation}
		\forall x \in \S \quad (f+g)(x) = f(x)+g(x)
	\end{equation}
	\item pour $f$ dans $\F(\S,E)$ et $\lambda$ dans $\K$, on définit l'application $\lambda f$ par~:
	\begin{equation}
		\forall x \in \S \quad (\lambda \cdot f)(x) = \lambda \cdot f(x)
	\end{equation}
\end{itemize}
On vérifie alors que $(\F(\S,E), +, \cdot)$ est un $\K$-espace vectoriel.
\section{Produit d'espaces vectoriels}
Soient $E_1, \cdots, E_p$ des $\K$-espaces vectoriels dont les lois sont toutes notées $+$ et $\cdot$ bien qu'elles soient différentes a priori. Le produit cartésien $E = E_1 \times \cdots \times E_p$ est muni des lois internes suivantes~:
\begin{align}
	\forall (x_1, \cdots, x_p) \in E \ \forall (y_1, \cdots, y_p) \in E \quad (x_1, \cdots, x_p) + (y_1, \cdots, y_p) &\overset{\text{def}}{=} (x_1+y_1, \cdots, x_p+y_p) \\
	\forall (x_1, \cdots, x_p) \in E \ \forall \lambda \in \K \quad \lambda (x_1, \cdots, x_p) &\overset{\text{def}}{=} (\lambda x_1, \cdots, \lambda x_p)
\end{align}
On vérifie alors que $E$ muni de ces deux lois est un $\K$-espace vectoriel, appelé espace vectoriel produit.
\section{Algèbre sur un corps}
Soit $\A$ un ensemble, $+$ et $\times$ des lois internes sur $\A$, $\cdot$ une loi externe sur $\A$ à opérateurs dans $\K$.
\begin{defdef}[Algèbre]
	$(\A,+,\times,\cdot)$ est une $\K$-algèbre si et seulement si~:
	\begin{itemize}
		\item $(\A,+,\cdot)$ est un $\K$-espace vectoriel
		\item $(\A,+,\times)$ est un anneau
		\item les deux produits sont compatibles~:
		\begin{equation}
			\forall x,y \in E \ \forall \lambda \in \K \quad (\lambda \cdot x) \times y = \lambda \cdot (x \times y) = x \times (\lambda \cdot y)
		\end{equation}
	\end{itemize}
\end{defdef}

Ces propriétés sont équivalentes aux douze propriétés suivantes~:
\begin{itemize}
	\item $(\A, +)$ est un groupe commutatif (cinq axiomes)~:
	\begin{itemize}
		\item[--- \textbf{Loi de composition interne}] Pour tous $x$ et $y$ de $\A$, $x+y$ est dans $\A$ ;
		\item[--- \textbf{Associativité}] Pour tous $x, y, z \in \A$, $(x+y)+z = x+(y+z)$ ;
		\item[--- \textbf{Neutre}] $0$ est le neutre pour $+$~: Pour tout $x \in \A$, $x+0=0+x=x$ ;
		\item[--- \textbf{Symétrique}] Pour tout $x$ de $\A$, il existe un élément $-a \in \A$ tel que $a+(-a) = -a+a = 0$.
		\item[--- \textbf{Commutativité}] Pour tous $x,y \in \A$, $x+y=y+x$
	\end{itemize}
	\item les  trois axiomes d'un $\K$-espace vectoriel~:
	\begin{itemize}
		\item $(\A, +)$ est un groupe commutatif (voir ci-dessus)
		\item La loi $\cdot$ est distributive à gauche par rapport à la loi $+$ de $\A$ et à droite par rapport à la loi $+$ du corps $\K$~:
		\begin{equation}
			\forall \lambda, \mu \in \K \ \forall x,y \in \A \quad \lambda \cdot (x+y) = \lambda \cdot x + \lambda \cdot y \quad (\lambda+\mu) \cdot x = \lambda \cdot x + \mu \cdot x 
		\end{equation}
	   	\item La loi $\cdot$ de $\A$ possède une associativité ``mixte'' avec la loi $\cdot$ de $\K$~:
	   	\begin{equation}
	   			\forall \lambda, \mu \in \K \ \forall x \in \A \quad (\lambda \cdot_\K \mu)\cdot_\A x = \lambda \cdot_\A (\mu \cdot_\A x)	
	   	\end{equation}
   		\item La loi $\cdot$ de $\A$ possède un élément neutre noté $1$~:
   			\begin{equation}
   			\forall x \in \A \quad 1 \cdot x = x \cdot 1 = x
   		\end{equation}
	\end{itemize}
	\item $\times$ est associative ;
	\item $\times$ est distributive par rapport à $+$ ;
	\item La loi $\times$ possède un élément neutre $e$ ;
	\item les deux produits sont compatibles
			\begin{equation}
				\forall x,y \in E \ \forall \lambda \in \K \quad (\lambda \cdot x) \times y = \lambda \cdot (x \times y) = x \times (\lambda \cdot y)
			\end{equation}	
\end{itemize}
Si la deuxième loi interne $\times$ est commutative, l'algèbre est commutative. Dans une algèbre $\A$, on a les mêmes règles de calculs que dans un anneau et dans un $\K$-espace vectoriel~:
\begin{align}
	\forall x \in \A &\quad 0_\A \times x = x \times 0_\A = 0_\A \\
	\forall x,y \in \A &\quad (-x) \times y = x \times (-y) = -(x\times y) \\
	\forall x \in \A \forall \lambda \in \K &\quad 0_\K \cdot x = \lambda \cdot 0_\A = 0_\A \\
	\forall x \in \A \forall \lambda \in \K &\quad -(\lambda \cdot x) = \lambda \cdot (-x) = (-\lambda)\cdot x
\end{align}
et la notation des itérés de $x$~: $nx$ avec $n \in \Z$ et $x^p$ avec $p \in \N$ ($0x=0_\A$ et $x^0=1_\A$).

Exercice~: Montrer que $nx = n \cdot x = (n1_\A) \times x$.

\paragraph{Exemples usuels}
$\K[X]$ muni des lois communes est une algèbre commutative. $(\Endo{E},+\circ,\cdot)$ et $(\Mn{n}{\K}, +, \times, \cdot)$ sont des algèbres non commutatives. L'ensemble des applications de $I$ dans $\K$, ou encore les familles de scalaires indexées par un ensemble $I$ sont des algèbres. En particulier $\R^\N$ (l'ensemble des suites réelles) et $\F(\R,\R) = \R^\R$ sont des $\R$-algèbres.

\paragraph{Sous-algèbre}
\begin{defdef}
	Soit $(\A,+,\times,\cdot)$ une $\K$-algèbre et $\B \subset A$ ;
	$\B$ est une sous-algèbre de $A$ si et seulement si $\B$ est un sous-espace vectoriel et un sous-anneau de $\A$ si et seulement si $\B$ est un sous-espace vectoriel de $\A$ et $1_\A \in \B$ et pour tous $x, y \in \B, x \times y \in \B$.
\end{defdef}

$\B$ muni des lois induites est alors une $\K$-algèbre. Une caractérisation équivalente en est~:
$\B$ est une sous-algèbre de $\A$  si et seulement si $1_\A \in \B$ et pour tous $x, y \in \B$ et tout $\lambda \in \K$ , $x \times y \in \B$, $\lambda x+y \in \B$.

\emph{Exemples}~:
\begin{itemize}
	\item $\classe{0}(\R,\R)$ est une sous-algèbre de $\R^\R$
	\item l'ensemble des suites bornées et celui des suites convergentes ailleurs qu'en zéro (puisque la suite égale à $1$ n'est pas dedans) sont bien des sous-algèbre de $\R^\N$
\end{itemize}
\paragraph{Morphisme d'algèbre}
\begin{defdef}
	Soient  $(\A,+,\times,\cdot)$ et $(\B,+,\times,\cdot)$ deux $\K$-algèbres et $\phi$ de $\A$ vers $\B$, alors $\phi$ est un morphisme d'algèbre si et seulement si c'est un morphisme d'espaces vectoriel et un morphisme d'anneaux.
\end{defdef}
Ainsi, $\phi$ est un morphisme d'algèbre si et seulement si~:
\begin{align}
	\forall x,y \in \A \ \forall \lambda \in \K \quad \phi(\lambda x+y) &= \lambda\phi(x)+\phi(y) \\
	\forall x,y \in \A \quad \phi(x \times y) &= \phi(x) \times \phi(y) \\
	\phi(1_\A) &= 1_\B
\end{align}

\emph{Ppté}~: Image directe et réciproque d'une sous-algèbre, \ldots

\emph{Exemple fondamental}~: Évaluation des polynômes de $\K[X]$ en $a \in \A$
\begin{prop}
	Soit 
	\begin{equation}
		\fonction{\Phi}{\K[X]}{\A}{P = \sum_{i=0}^d \lambda_i X^i}{\Phi(P) = \sum_{i=0}^d\lambda_i a^i=P(A)},
	\end{equation} 
	alors~:
	\begin{enumerate}
		\item $\Phi$ est un morphisme de $\K$-algèbres ;
		\item $\Image{\Phi}$ est une sous-algèbre commutative de $\A$ noté $\K[a]$ (polynômes en $a$) ;
		\item $\K[a]$ est la plus petite sous-algèbre de $\A$ contenant $a$. $\K[a]$ est la sous-algèbre engendrée par $a$.
	\end{enumerate}
\end{prop}

\section{Familles de vecteurs}
\subsection{Définition}
Soient $I$ et $E$ des ensembles non vides.

Une famille d'éléments de $E$ indexées par $I$ est une application, $x$, de $I$ dans $E$ que l'on note $x=(x_i)_{i \in I}$ telle que $\fonction{x}{I}{E}{i}{x_i}$. L'entier $i$  est appelé l'indice et $x_i$ l'élément de la famille bien qu'à proprement parler il n'appartient pas à la famille puisque cette famille n'est pas un ensemble.

Si $J$ est un sous-ensemble non vide de $I$, alors la restriction à $J$ de l'application $x$, noté $(x_i)_{i \in J}$ est une sous-famille de $(x_i)_{i \in I}$. Inversement, $(x_i)_{i \in I}$ est une sur-famille de $(x_i)_{i \in J}$.

L'ensemble des familles d'éléments de $E$ indexée par $I$ est noté $E^I$.

\emph{Dans toute la suite de ce chapitre $E$ désignera un $\K$-espace vectoriel.}

$E^I$ et $\K^I$ sont naturellement des $\K$-espaces vectoriels et on en rappelle les lois~:
\begin{align}
	\forall \lambda \in \K \quad \forall x,y \in E^I \quad (\lambda x +y)_{i \in I} = \lambda x_{i\in I} + y_{i\in I}	
\end{align}

\paragraph{Famille presque nulle de scalaires}
Une famille $(\lambda)_{i \in I}$ d'éléments d'un corps $\K$ est dite \emph{presque nulle} si son ``support'' $J =\enstq{i \in I}{\lambda_i \neq 0}$ est un ensemble fini. L'ensemble des familles presque nulle est noté $\K^{(I)}$ et c'est un sous-espace vectoriel de $\K^I$.

\paragraph{Combinaisons linéaires}
Soit $X=(x_i)_{i \in I}$ une famille de vecteurs de $E$ indexée par un ensemble quelconque $I$. Une \emph{combinaison linéaire} des vecteurs de la famille $X$ est un vecteur pouvant s'écrire~: $x = \sum_{i \in I} \lambda_i x_i$, où $\lambda$ est une famille \emph{presque nulle} de scalaires. Remarquez que cette somme a bien un sens et désigne la somme (commutative) d'un nombre \emph{fini} de vecteurs de $E$.

\subsection{Familles libres, familles génératrice}

Soit $(x_i)_{i \in I} \in E^I$, on définit~:
\begin{align}
	(x_i)_{i \in I} \text{ est libre } &\iff \forall (\lambda_i)_{i \in I} \in \K^{(I)} \; \left(\sum_{i \in I} \lambda_i x_i = 0 \implies \forall i \in I \ \lambda_i=0 \right) \\
	(x_i)_{i \in I} \text{ est génératrice } &\iff \forall x \in E \ \exists  (\lambda_i)_{i \in I} \in \K^{(I)} \; x = \sum_{i \in I} \lambda_i x_i
\end{align}

La famille $(x_i)_{i \in I}$ est dite \emph{liée} si elle n'est pas libre. une relation $\sum_{i \in I} \lambda_i x_i = 0$ avec des scalaires presque tous nuls mais \emph{non tous nuls} est appelée une relation de liaison entre ces vecteurs.

La famille $(x_i)_{i \in I}$ est appelée une \emph{base} de l'espace vectoriel $E$ si elle est à la fois libre et génératrice. On constate l'équivalence suivante~:
\begin{equation}
	(x_i)_{i \in I} \text{ est une base de } E \iff \forall x \in E \ \exists !  (\lambda_i)_{i \in I} \in \K^{(I)} \; x = \sum_{i \in I} \lambda_i x_i.
\end{equation}
Cette fois un vecteur $x$ de $E$ peut s'écrire d'une \emph{unique façon} comme combinaison linéaire des vecteurs de la famille $(x_i)_{i \in I}$ et la famille $(\lambda_i)_{i \in I}$ intervenant est appelé le \emph{système de coordonnées} de $x$ sur la base $(x_i)_{i \in I}$.

L'application suivante est alors un isomorphisme d'espaces vectoriels~:
\begin{equation}
	\fonction{\phi}{\K^{(I)}}{E}{(\lambda_{i \in I})}{\sum_{i \in I} \lambda_i x_i}
\end{equation}

\emph{On admettra que dans tout espace vectoriel il existe des bases.}

\paragraph{Glissement de notation}
Si $I$ est un ensemble \emph{fini} de cardinal $p$, généralement $I = \intervalleentier{1}{p}$, on note souvent $(x_i)_{1 \leqslant i \leqslant p}$ voire même $(x_1, \cdots, x_p)$ au lieu de $(x_i)_{i \in \{1, 2, \cdots, p\}}$. On réécris les définitions dans ce cas~:
\begin{align}
	(x_1, \cdots, x_p) \text{ est libre } &\iff \forall (\lambda_1, \cdots, \lambda_p) \in \K^{p} \; \sum_{i=1}^p \lambda_i x_i = 0 \implies \lambda_1=\cdots=\lambda_p=0 \\
	(x_1, \cdots, x_p) \text{ est génératrice } &\iff \forall x \in E \ \exists  (\lambda_1, \cdots, \lambda_p) \in \K^{p} \; x = \lambda_1 x_1 + \cdots + \lambda_p x_p \\
	(x_1, \cdots, x_p) \text{ est une base de } E &\iff \forall x \in E \ \exists ! (\lambda_1, \cdots, \lambda_p) \in \K^{p} \; x = \lambda_1 x_1 + \cdots + \lambda_p x_p.
\end{align}

\emph{Exemples}~:
\begin{enumerate}
	\item Dans le $\R$-espace vectoriel $\C$, la famille $(1, 1+\ii, 1, i)$ est liée et la famille $(1, 1+i)$ est libre.
	\item Base canonique de $\K^p$~: $e_1 = (1,0,\cdots,0)$, $e_2 = (0,1,\cdots,0)$, \ldots, $e_p = (0,0,\cdots,1)$.
	\item Base canonique de $\K[X]$~: $(X^n)_{n \in \N}$.
\end{enumerate}

\subsection{Propriétés élémentaires}

Lorsque $I$ est infini, $(x_i)_{i \in I}$ est libre si et seulement si toute sous-famille finie (\emph{id est} dont l'ensemble d'indices est fini) est libre.

Toute sous-famille d'une famille libre est libre. Toute sur-famille d'une famille liée est liée.

Si la famille $(x_i)_{i \in I}$, $I$ quelconque, est libre alors~:
\begin{itemize}
	\item $\forall i \in I \quad x_i \neq 0$
	\item L'application $\fonction{\Phi}{I}{E}{i}{x_i}$ (appelée indexation mais c'est en fait la famille elle-même) est injective
	\item Lorsque $I$ est fini, $\Card\enstq{x_i}{i \in I} = \Card I$.
\end{itemize}

Si $(x_i)_{i \in I}$ est une base de $E$ et $(y_i)_{i \in I}$ une famille quelconque de vecteurs de $F$, alors il existe une et une seule application linéaire $f$ de $E$ dans $F$ telle que pour tout $i \in I$, $f(x_i) = y_i$.

\emph{Exemples}~:
Si on note $\fonction{f_\alpha}{\R}{\R}{x}{\e^{\alpha x}}$, la famille $(f_\alpha)_{\alpha \in \R}$ est libre dans le $\R$-espace vectoriel $\R^\R$.
Si on note $\fonction{g_n}{\R}{\C}{x}{x\e^{\ii n \frac{\pi}{7}}}$, la famille $(g_n)_{n \in \N}$ est libre dans le $\C$-espace vectoriel $\C^\R$.

\subsection{Algèbre des fonctions polynômiales à $n$ variables $\K[x_1, \cdots, x_n]$}

\begin{defdef}
	Une application $f$ de $\K^n$ dans $\K$ est dite polynômiale à $n$ variables s'il existe une famille presque nulle de scalaires indexée par $\N^n$  $(a_i)_{i \in \N^n}$ telle que~:
	\begin{equation}
		\forall (x_1, \cdots, x_n) \in \K^n \quad f(x_1, \cdots, x_n) = \sum_{(i_1, \cdots, i_n) \in \N^n} a_{(i_1, \cdots, i_n)} x_1^{i_1} x_2^{i_2} \cdots x_n^{i_n}
	\end{equation}
\end{defdef}

\begin{remarque}
	Ici, $(a_i)_{i \in \N^n} \in \K^{(\N^n)}$.
\end{remarque}
\begin{exemple}
	$(x,y,z) \overset{f}{\longmapsto} 1-2x+y^4+3xyz^5$ est une fonction polynômiale à trois variables réelles. Ici, $n=3$, $a_{(0,0,0)}=1$, $a_{(1,0,0)}=-2$, $a_{(0,4,0)}=1$, $a_{(1,1,5)}=3$ et les autres sont nuls.
\end{exemple}
\begin{prop}
	L'ensemble $\K[x_1, \cdots, x_n]$ des fonctions polynômiales à $n$ variables dans $\K$ est une sous-algèbre de $\F(\K^n, \K)$.
\end{prop}
\begin{prop}
	Pour $i = (i_n, \cdots, i_n) \in \N^n$, on pose $p_i : (x_1, \cdots, x_n) \longmapsto x_1^{i_1} x_2^{i_2} \cdots x_n^{i_n}$. La famille $(p_i)_{i \in \N^n}$ est une base de $\K[x_1, \cdots, x_n]$.
\end{prop}
\begin{proof}
	Elle est génératrice par définition. Montrons qu'elle est libre par récurrence sur $n$~:
	Soit $(a_i)_{i \in \N^n} \in \K^{(\N^n)}$ telle que $\sum_{i \in \N^n} a_i p_i =0$. Notons $J \subset \N^n$ le support fini de $I$. On a donc~:
	\begin{equation}
		\label{eq:etoile}
		\forall (x_1, \cdots, x_n) \in \K^n \quad \sum_{i \in J} a_i x_1^{i_1} x_2^{i_2} \cdots x_n^{i_n} = 0.
	\end{equation}
	On ordonne cette relation suivant les puissances de $x_n$ en posant $N = \max\{i_n, i \in J\}$ et pour $k \in \intervalleentier{0}{N}$~: $J_k = \enstq{i \in J}{i_n=k}$. De sorte que si $P_k(x_1, \cdots, x_{n-1}) = \sum_{i \in J_k} a_i x_1^{i_1} x_2^{i_2} \cdots x_{n-1}^{i_{n-1}}$, alors \eqref{eq:etoile} devient~:
	\begin{equation}
		\forall (x_1, \cdots, x_n) \in \K^n \quad \sum_{k=0}^N P_k(x_1, \cdots, x_{n-1}) x_n^k = 0.
	\end{equation}
	\ldots
\end{proof}

\section{Sommes de sous-espaces vectoriels}
\subsection{Définitions}